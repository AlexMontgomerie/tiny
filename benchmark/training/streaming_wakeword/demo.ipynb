{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386153cd-684f-4bca-a6ad-eca4bcccfb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremy/miniforge3/envs/jh_main/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.lite.experimental.microfrontend.python.ops import audio_microfrontend_op as frontend_op\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "import functools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, pickle\n",
    "\n",
    "import str_ww_util as util\n",
    "import keras_model as models\n",
    "\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6132467-f897-42fe-a324-edd03ba13f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db02f34-2ff4-43b2-b86d-0b46f3a4d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int16(sample_dict):\n",
    "  audio = sample_dict['audio']\n",
    "  label = sample_dict['label']\n",
    "  audio16 = tf.cast(audio, 'int16')\n",
    "  return audio16, label\n",
    "\n",
    "def cast_and_pad(sample_dict):\n",
    "  audio = sample_dict['audio']\n",
    "  label = sample_dict['label']\n",
    "  paddings = [[0, 16000-tf.shape(audio)[0]]]\n",
    "  audio = tf.pad(audio, paddings)\n",
    "  audio16 = tf.cast(audio, 'int16')\n",
    "  return audio16, label\n",
    "\n",
    "def convert_dataset(item):\n",
    "  \"\"\"Puts the mnist dataset in the format Keras expects, (features, labels).\"\"\"\n",
    "  audio = item['audio']\n",
    "  label = item['label']\n",
    "  return audio, label\n",
    "\n",
    "\n",
    "def get_preprocess_audio_func(model_settings,is_training=False,background_data = []):\n",
    "  def prepare_processing_graph(next_element):\n",
    "    \"\"\"Builds a TensorFlow graph to apply the input distortions.\n",
    "    Creates a graph that loads a WAVE file, decodes it, scales the volume,\n",
    "    shifts it in time, adds in background noise, calculates a spectrogram, and\n",
    "    then builds an MFCC fingerprint from that.\n",
    "    This must be called with an active TensorFlow session running, and it\n",
    "    creates multiple placeholder inputs, and one output:\n",
    "      - wav_filename_placeholder_: Filename of the WAV to load.\n",
    "      - foreground_volume_placeholder_: How loud the main clip should be.\n",
    "      - time_shift_padding_placeholder_: Where to pad the clip.\n",
    "      - time_shift_offset_placeholder_: How much to move the clip in time.\n",
    "      - background_data_placeholder_: PCM sample data for background noise.\n",
    "      - background_volume_placeholder_: Loudness of mixed-in background.\n",
    "      - mfcc_: Output 2D fingerprint of processed audio.\n",
    "    Args:\n",
    "      model_settings: Information about the current model being trained.\n",
    "    \"\"\"\n",
    "    desired_samples = model_settings['desired_samples']\n",
    "    background_frequency = model_settings['background_frequency']\n",
    "    background_volume_range_= model_settings['background_volume_range_']\n",
    "\n",
    "    wav_decoder = tf.cast(next_element['audio'], tf.float32)\n",
    "    if model_settings['feature_type'] != \"td_samples\":\n",
    "      wav_decoder = wav_decoder/tf.reduce_max(wav_decoder)\n",
    "    else:\n",
    "      wav_decoder = wav_decoder/tf.constant(2**15,dtype=tf.float32)\n",
    "    #Previously, decode_wav was used with desired_samples as the length of array. The\n",
    "    # default option of this function was to pad zeros if the desired samples are not found\n",
    "    wav_decoder = tf.pad(wav_decoder,[[0,desired_samples-tf.shape(wav_decoder)[-1]]]) \n",
    "    # Allow the audio sample's volume to be adjusted.\n",
    "    foreground_volume_placeholder_ = tf.constant(1,dtype=tf.float32)\n",
    "    \n",
    "    scaled_foreground = tf.multiply(wav_decoder,\n",
    "                                    foreground_volume_placeholder_)\n",
    "    # Shift the sample's start position, and pad any gaps with zeros.\n",
    "    time_shift_padding_placeholder_ = tf.constant([[2,2]], tf.int32)\n",
    "    time_shift_offset_placeholder_ = tf.constant([2],tf.int32)\n",
    "    scaled_foreground.shape\n",
    "    padded_foreground = tf.pad(scaled_foreground, time_shift_padding_placeholder_, mode='CONSTANT')\n",
    "    sliced_foreground = tf.slice(padded_foreground, time_shift_offset_placeholder_, [desired_samples])\n",
    "  \n",
    "    if is_training and background_data != []:\n",
    "      background_volume_range = tf.constant(background_volume_range_,dtype=tf.float32)\n",
    "      background_index = np.random.randint(len(background_data))\n",
    "      background_samples = background_data[background_index]\n",
    "      background_offset = np.random.randint(0, len(background_samples) - desired_samples)\n",
    "      background_clipped = background_samples[background_offset:(background_offset + desired_samples)]\n",
    "      background_clipped = tf.squeeze(background_clipped)\n",
    "      background_reshaped = tf.pad(background_clipped,[[0,desired_samples-tf.shape(wav_decoder)[-1]]])\n",
    "      background_reshaped = tf.cast(background_reshaped, tf.float32)\n",
    "      if np.random.uniform(0, 1) < background_frequency:\n",
    "        background_volume = np.random.uniform(0, background_volume_range_)\n",
    "      else:\n",
    "        background_volume = 0\n",
    "      background_volume_placeholder_ = tf.constant(background_volume,dtype=tf.float32)\n",
    "      background_data_placeholder_ = background_reshaped\n",
    "      background_mul = tf.multiply(background_data_placeholder_,\n",
    "                           background_volume_placeholder_)\n",
    "      background_add = tf.add(background_mul, sliced_foreground)\n",
    "      sliced_foreground = tf.clip_by_value(background_add, -1.0, 1.0)\n",
    "    \n",
    "    if model_settings['feature_type'] == 'mfcc':\n",
    "      stfts = tf.signal.stft(sliced_foreground, frame_length=model_settings['window_size_samples'], \n",
    "                         frame_step=model_settings['window_stride_samples'], fft_length=None,\n",
    "                         window_fn=tf.signal.hann_window\n",
    "                         )\n",
    "      spectrograms = tf.abs(stfts)\n",
    "      num_spectrogram_bins = stfts.shape[-1]\n",
    "      # default values used by contrib_audio.mfcc as shown here\n",
    "      # https://kite.com/python/docs/tensorflow.contrib.slim.rev_block_lib.contrib_framework_ops.audio_ops.mfcc\n",
    "      lower_edge_hertz, upper_edge_hertz, num_mel_bins = 20.0, 4000.0, 40 \n",
    "      linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix( num_mel_bins, num_spectrogram_bins,\n",
    "                                                                           model_settings['sample_rate'],\n",
    "                                                                           lower_edge_hertz, upper_edge_hertz)\n",
    "      mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "      mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
    "      # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "      log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "      # Compute MFCCs from log_mel_spectrograms and take the first 13.\n",
    "      mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :model_settings['dct_coefficient_count']]\n",
    "      mfccs = tf.reshape(mfccs,[model_settings['spectrogram_length'], model_settings['dct_coefficient_count'], 1])\n",
    "      next_element['audio'] = mfccs\n",
    "      #next_element['label'] = tf.one_hot(next_element['label'],12)\n",
    "\n",
    "    elif model_settings['feature_type'] == 'lfbe':\n",
    "      # apply preemphasis\n",
    "      preemphasis_coef = 1 - 2 ** -5\n",
    "      power_offset = 52\n",
    "      num_mel_bins = model_settings['dct_coefficient_count']\n",
    "      paddings = tf.constant([[0, 0], [1, 0]])\n",
    "      # for some reason, tf.pad only works with the extra batch dimension, but then we remove it after pad\n",
    "      sliced_foreground = tf.expand_dims(sliced_foreground, 0)\n",
    "      sliced_foreground = tf.pad(tensor=sliced_foreground, paddings=paddings, mode='CONSTANT')\n",
    "      sliced_foreground = sliced_foreground[:, 1:] - preemphasis_coef * sliced_foreground[:, :-1]\n",
    "      sliced_foreground = tf.squeeze(sliced_foreground) \n",
    "      # compute fft\n",
    "      stfts = tf.signal.stft(sliced_foreground,  frame_length=model_settings['window_size_samples'], \n",
    "                             frame_step=model_settings['window_stride_samples'], fft_length=None,\n",
    "                             window_fn=functools.partial(\n",
    "                               tf.signal.hamming_window, periodic=False),\n",
    "                             pad_end=False,\n",
    "                             name='STFT')\n",
    "    \n",
    "      # compute magnitude spectrum [batch_size, num_frames, NFFT]\n",
    "      magspec = tf.abs(stfts)\n",
    "      num_spectrogram_bins = magspec.shape[-1]\n",
    "    \n",
    "      # compute power spectrum [num_frames, NFFT]\n",
    "      powspec = (1 / model_settings['window_size_samples']) * tf.square(magspec)\n",
    "      powspec_max = tf.reduce_max(input_tensor=powspec)\n",
    "      powspec = tf.clip_by_value(powspec, 1e-30, powspec_max) # prevent -infinity on log\n",
    "    \n",
    "      def log10(x):\n",
    "        # Compute log base 10 on the tensorflow graph.\n",
    "        # x is a tensor.  returns log10(x) as a tensor\n",
    "        numerator = tf.math.log(x)\n",
    "        denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "        return numerator / denominator\n",
    "    \n",
    "      # Warp the linear-scale, magnitude spectrograms into the mel-scale.\n",
    "      lower_edge_hertz, upper_edge_hertz = 0.0, model_settings['sample_rate'] / 2.0\n",
    "      linear_to_mel_weight_matrix = (\n",
    "          tf.signal.linear_to_mel_weight_matrix(\n",
    "              num_mel_bins=num_mel_bins,\n",
    "              num_spectrogram_bins=num_spectrogram_bins,\n",
    "              sample_rate=model_settings['sample_rate'],\n",
    "              lower_edge_hertz=lower_edge_hertz,\n",
    "              upper_edge_hertz=upper_edge_hertz))\n",
    "\n",
    "      mel_spectrograms = tf.tensordot(powspec, linear_to_mel_weight_matrix,1)\n",
    "      mel_spectrograms.set_shape(magspec.shape[:-1].concatenate(\n",
    "          linear_to_mel_weight_matrix.shape[-1:]))\n",
    "\n",
    "      log_mel_spec = 10 * log10(mel_spectrograms)\n",
    "      log_mel_spec = tf.expand_dims(log_mel_spec, -1, name=\"mel_spec\")\n",
    "    \n",
    "      log_mel_spec = (log_mel_spec + power_offset - 32 + 32.0) / 64.0\n",
    "      log_mel_spec = tf.clip_by_value(log_mel_spec, 0, 1)\n",
    "\n",
    "      next_element['audio'] = log_mel_spec\n",
    "\n",
    "    elif model_settings['feature_type'] == 'td_samples':\n",
    "      ## sliced_foreground should have the right data.  Make sure it's the right format (int16)\n",
    "      # and just return it.\n",
    "      paddings = [[0, 16000-tf.shape(sliced_foreground)[0]]]\n",
    "      wav_padded = tf.pad(sliced_foreground, paddings)\n",
    "      wav_padded = tf.expand_dims(wav_padded, -1)\n",
    "      wav_padded = tf.expand_dims(wav_padded, -1)\n",
    "      next_element['audio'] = wav_padded\n",
    "      \n",
    "    return next_element\n",
    "  \n",
    "  return prepare_processing_graph\n",
    "\n",
    "\n",
    "def prepare_background_data(bg_path,BACKGROUND_NOISE_DIR_NAME):\n",
    "  \"\"\"Searches a folder for background noise audio, and loads it into memory.\n",
    "  It's expected that the background audio samples will be in a subdirectory\n",
    "  named '_background_noise_' inside the 'data_dir' folder, as .wavs that match\n",
    "  the sample rate of the training data, but can be much longer in duration.\n",
    "  If the '_background_noise_' folder doesn't exist at all, this isn't an\n",
    "  error, it's just taken to mean that no background noise augmentation should\n",
    "  be used. If the folder does exist, but it's empty, that's treated as an\n",
    "  error.\n",
    "  Returns:\n",
    "    List of raw PCM-encoded audio samples of background noise.\n",
    "  Raises:\n",
    "    Exception: If files aren't found in the folder.\n",
    "  \"\"\"\n",
    "  background_data = []\n",
    "  background_dir = os.path.join(bg_path, BACKGROUND_NOISE_DIR_NAME)\n",
    "  if not os.path.exists(background_dir):\n",
    "    return background_data\n",
    "  #with tf.Session(graph=tf.Graph()) as sess:\n",
    "  #    wav_filename_placeholder = tf.placeholder(tf.string, [])\n",
    "  #    wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
    "  #    wav_decoder = contrib_audio.decode_wav(wav_loader, desired_channels=1)\n",
    "  search_path = os.path.join(bg_path, BACKGROUND_NOISE_DIR_NAME,'*.wav')\n",
    "  #for wav_path in gfile.Glob(search_path):\n",
    "  #    wav_data = sess.run(wav_decoder, feed_dict={wav_filename_placeholder: wav_path}).audio.flatten()\n",
    "  #    self.background_data.append(wav_data)\n",
    "  for wav_path in gfile.Glob(search_path):\n",
    "    #audio = tfio.audio.AudioIOTensor(wav_path)\n",
    "    raw_audio = tf.io.read_file(wav_path)\n",
    "    audio = tf.audio.decode_wav(raw_audio)\n",
    "    background_data.append(audio[0])\n",
    "  if not background_data:\n",
    "    raise Exception('No background wav files were found in ' + search_path)\n",
    "  return background_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b4f73-69c0-40a0-b9a4-fb67cadb0c38",
   "metadata": {},
   "source": [
    "## Process Files into TF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae79cbe-d3e8-40ca-92fa-d185a88be2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):\n",
    "  # Decode WAV-encoded audio files to `float32` tensors, normalized\n",
    "  # to the [-1.0, 1.0] range. Return `float32` audio and a sample rate.\n",
    "  audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "  # Since all the data is single channel (mono), drop the `channels`\n",
    "  # axis from the array.\n",
    "  return tf.squeeze(audio, axis=-1)\n",
    "  \n",
    "def get_label(file_path):\n",
    "  parts = tf.strings.split(\n",
    "      input=file_path,\n",
    "      sep=os.path.sep)\n",
    "  # Note: You'll use indexing here instead of tuple unpacking to enable this\n",
    "  # to work in a TensorFlow graph.\n",
    "  return parts[-2]\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  audio_binary = tf.io.read_file(file_path)\n",
    "  waveform = decode_audio(audio_binary)\n",
    "  return {'audio':waveform, 'label':label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7e9acc-ef62-4da2-a7a0-00ef04751175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_str2int(datum):\n",
    "  \"\"\"\n",
    "  datum is {'audio':<audio>, 'label':<label_as_string>} \n",
    "  returns {'audio':<audio>, 'label':<label_as_int>}\n",
    "  according to:\n",
    "        keys=tf.constant([\"marvin\", \"_silence\", \"_unknown\"]),\n",
    "        values=tf.constant([0, 1, 2]),\n",
    "  \"\"\"\n",
    "  # build a lookup table\n",
    "  label_map = tf.lookup.StaticHashTable(\n",
    "      initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "          keys=tf.constant([\"marvin\", \"_silence\", \"_unknown\"]),\n",
    "          values=tf.constant([0, 1, 2]),\n",
    "      ),\n",
    "      default_value=tf.constant(2), # map other labels to _unknown\n",
    "      name=\"class_labels\"\n",
    "  )\n",
    "  \n",
    "  return {'audio': datum['audio'], \n",
    "          'label':label_map.lookup(datum['label'])\n",
    "         }\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35f5b7d-a90e-473a-bfc2-484953a57b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(ds):\n",
    "  label_counts = {}\n",
    "  for i in range(12): label_counts[i] = 0\n",
    "  for dat in ds:\n",
    "    new_label = dat['label'].numpy()\n",
    "    if new_label in label_counts:\n",
    "      label_counts[new_label] += 1\n",
    "    else:\n",
    "      label_counts[new_label] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad0441-25e8-4167-b9b1-4a792da509f6",
   "metadata": {},
   "source": [
    "## Done definining functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0df306e-432a-4f12-a73a-cc945341dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flags, unparsed = util.parse_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b889317-b130-4b06-97a6-93713873e60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 08:42:20.181367: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-01-29 08:42:20.181389: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-01-29 08:42:20.181393: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-01-29 08:42:20.181428: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-29 08:42:20.181444: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "Flags.num_train_samples = 50\n",
    "Flags.num_val_samples = 50\n",
    "Flags.num_test_samples = 50\n",
    "\n",
    "Flags.data_dir = os.path.join(os.getenv('HOME'), 'data', 'speech_commands_files_0.2')\n",
    "Flags.bg_path = Flags.data_dir\n",
    "\n",
    "val_cal_subset=False\n",
    "get_waves = False\n",
    "\n",
    "BACKGROUND_NOISE_DIR_NAME='_background_noise_' \n",
    "background_data = prepare_background_data(Flags.bg_path,BACKGROUND_NOISE_DIR_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a182fc-e9bf-4e03-a793-01d94561a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_train, ds_test, ds_val = get_training_data(Flags)\n",
    "\n",
    "label_count=3\n",
    "background_frequency = Flags.background_frequency\n",
    "background_volume_range_= Flags.background_volume\n",
    "model_settings = models.prepare_model_settings(label_count, Flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11dcac38-325e-4681-b021-41b4f7b6f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Code for loading data from pre-built dataset.  We're loading from files,\n",
    "## because we need the 'marvin' keyword\n",
    "# splits = ['train', 'test', 'validation']\n",
    "# (ds_train, ds_test, ds_val), ds_info = tfds.load('speech_commands:0.0.2', split=splits, \n",
    "#                                               data_dir=Flags.data_dir, with_info=True)\n",
    "## class 10 = background noise\n",
    "## class 11 = 'other words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfa5d9b-f0b2-4a0e-b14c-1c98e6bdeb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_count = 5\n",
    "# count = 0\n",
    "# for dat in ds_train:\n",
    "#   # print(dat['label'])\n",
    "#   if dat['label'].numpy() == 10: \n",
    "#     count += 1\n",
    "#     display.display(display.Audio(dat['audio'].numpy(), rate=16000))\n",
    "#     if count >= max_count:\n",
    "#       break\n",
    "# # display.display(display.Audio(dat['audio'].numpy(), rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbfcbfa-6eb9-482d-9cf4-2d85da5e3457",
   "metadata": {},
   "source": [
    "#### Build Dataset from Files\n",
    "Right here is where we should build a dataset from files.\n",
    "each dataset element should be {'audio':<waveform>, 'label':<integer_label>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bad90a4-595c-4a28-8c60-d447eb409bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Flags.data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de234fbb-c72e-4831-b90f-956451b25211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "filenames = glob.glob(os.path.join(str(data_dir), '*', '*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8b2a9dc-3d73-41f7-8fb0-2ebeb85b169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full speech-commands set lists which files are to be used\n",
    "# as test and validation data; train with everything else\n",
    "data_dir = Flags.data_dir\n",
    "fname_val_files = os.path.join(data_dir, 'validation_list.txt')    \n",
    "with open(fname_val_files) as fpi_val:\n",
    "  val_files = fpi_val.read().splitlines()\n",
    "# validation_list.txt only lists partial paths, append to data_dir and sr\n",
    "val_files = [os.path.join(data_dir, fn).rstrip() for fn in val_files]\n",
    "\n",
    "# repeat for test files\n",
    "fname_test_files = os.path.join(data_dir, 'testing_list.txt')\n",
    "with open(fname_test_files) as fpi_tst:\n",
    "  test_files = fpi_tst.read().splitlines()  \n",
    "test_files = [os.path.join(data_dir, fn).rstrip() for fn in test_files]    \n",
    "  \n",
    "if os.sep != '/': \n",
    "  # the files validation_list.txt and testing_list.txt use '/' as path separator\n",
    "  # if we're on a windows machine, replace the '/' with the correct separator\n",
    "  val_files = [fn.replace('/', os.sep) for fn in val_files]\n",
    "  test_files = [fn.replace('/', os.sep) for fn in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64906d26-aa0b-4531-bc18-a331e74ee2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# don't train with the _background_noise_ files; exclude when directory name starts with '_'\n",
    "train_files = [f for f in filenames if f.split(os.sep)[-2][0] != '_']\n",
    "# validation and test files are listed explicitly in *_list.txt; train with everything else\n",
    "train_files = list(set(train_files) - set(test_files) - set(val_files))\n",
    "# now convert into a TF tensor so we can use the tf.dataset pipeline\n",
    "train_files = tf.constant(train_files)\n",
    "\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "ds_train = ds_train.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.map(convert_labels_str2int)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_tensor_slices(val_files)\n",
    "ds_val = ds_val.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "ds_val = ds_val.map(convert_labels_str2int)\n",
    "\n",
    "ds_test = tf.data.Dataset.from_tensor_slices(test_files)\n",
    "ds_test = ds_test.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_test.map(convert_labels_str2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "507e7e36-e103-487a-b276-16c7ac17b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One element from the training set:\n",
      "Input tensor shape: (16000,)\n",
      "Label = 2; shape = ()\n"
     ]
    }
   ],
   "source": [
    "for dat in ds_train.take(1):\n",
    "  print(\"One element from the training set:\")\n",
    "  print(f\"Input tensor shape: {dat['audio'].shape}\")  \n",
    "  print(f\"Label = {dat['label']}; shape = {dat['label'].shape}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96affd54-8afb-4ff7-852c-ad524afb6f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Flags.num_train_samples != -1:\n",
    "  ds_train = ds_train.take(Flags.num_train_samples)\n",
    "if Flags.num_val_samples != -1:\n",
    "  ds_val = ds_val.take(Flags.num_val_samples)\n",
    "if Flags.num_test_samples != -1:\n",
    "  ds_test = ds_test.take(Flags.num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "694a3bb9-2566-4562-b249-d671927017d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_waves:\n",
    "  ds_train = ds_train.map(cast_and_pad)\n",
    "  ds_test  =  ds_test.map(cast_and_pad)\n",
    "  ds_val   =   ds_val.map(cast_and_pad)\n",
    "else:\n",
    "  # extract spectral features and add background noise\n",
    "  ds_train = ds_train.map(get_preprocess_audio_func(model_settings,is_training=True,\n",
    "                                                    background_data=background_data),\n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  ds_test  =  ds_test.map(get_preprocess_audio_func(model_settings,is_training=False,\n",
    "                                                    background_data=background_data),\n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  ds_val   =   ds_val.map(get_preprocess_audio_func(model_settings,is_training=False,\n",
    "                                                    background_data=background_data),\n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "  # change output from a dictionary to a feature,label tuple\n",
    "  ds_train = ds_train.map(convert_dataset)\n",
    "  ds_test = ds_test.map(convert_dataset)\n",
    "  ds_val = ds_val.map(convert_dataset)\n",
    "\n",
    "# Now that we've acquired the preprocessed data, either by processing or loading,\n",
    "ds_train = ds_train.batch(Flags.batch_size)\n",
    "ds_test = ds_test.batch(Flags.batch_size)  \n",
    "ds_val = ds_val.batch(Flags.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7760335b-0232-41b5-b5f1-272d9c6d5a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One element from the training set has shape:\n",
      "Input tensor shape: (49, 40, 1)\n",
      "Label shape: ()\n",
      "Label : 2\n"
     ]
    }
   ],
   "source": [
    "for dat in ds_train.unbatch().take(1):\n",
    "  print(\"One element from the training set has shape:\")\n",
    "  print(f\"Input tensor shape: {dat[0].shape}\")\n",
    "  print(f\"Label shape: {dat[1].shape}\")\n",
    "  print(f\"Label : {dat[1]}\")\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b3ea42-85b6-4d24-a61e-d22c89250351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 49, 0: 1}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_count = 5\n",
    "count = 0\n",
    "label_counts = {}\n",
    "\n",
    "for dat in ds_train.unbatch():\n",
    "  # label_string = dat[1].numpy().decode('utf8')\n",
    "  label = dat[1].numpy()\n",
    "  if label in label_counts:\n",
    "    label_counts[label] += 1\n",
    "  else:\n",
    "    label_counts[label] = 1\n",
    "  # print(dat['label'])\n",
    "  if dat[1] == tf.constant(0):\n",
    "    count += 1\n",
    "    plt.subplot(1,max_count, count)\n",
    "    # display.display(display.Audio(dat[0].numpy(), rate=16000))\n",
    "    plt.imshow(dat[0].numpy())\n",
    "    if count >= max_count:\n",
    "      break\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc03d5e-0010-454c-9ce6-0780da660dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d88172-df6d-422b-a9ec-a47da6958ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
